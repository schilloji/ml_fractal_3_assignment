{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "129EFx7-_IXMTsE56BHCpMvnhrBpiiz_S",
      "authorship_tag": "ABX9TyNya8YFb58q+tvMBWpdW6RH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/schilloji/ml_fractal_3_assignment/blob/build/problem_3_task_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Hx_-Uxqvhr-Z"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import os\n",
        "import shutil\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pretain_path='/content/drive/MyDrive/data/charts/alexnet/'\n",
        "label_path = '/content/drive/MyDrive/data/charts/'\n",
        "lbl_df=pd.read_csv(label_path+str('train_val.csv'))\n",
        "\n",
        "'''\n",
        "I am using Pytorch Implementation for building the alexnet pretraining model. To prepare the data, we need to have the images into the respective\n",
        "folders of classes. Since we have one folder for all the images and labels in excel file, I will creating 5 folders for all the 5 classe and moving all the resprective images\n",
        "to the those folders.\n",
        "\n",
        "The below code creates the /alexnet folder inside the /charts folder and inside the /alexnet folder we creates the below folders\n",
        "/dot_line\n",
        "/pie\n",
        "/hbar_categorical\n",
        "/line\n",
        "/vbar_categorical\n",
        "'''\n",
        "try:\n",
        "  os.mkdir(label_path+str('alexnet'))\n",
        "  for i in lbl_df['type'].unique():  \n",
        "    class_path=pretain_path+str(i)\n",
        "    if os.path.exists(class_path):\n",
        "      pass\n",
        "    else:\n",
        "      os.mkdir(class_path)\n",
        "except OSError as e:\n",
        "  print(f\"No need to create {e}\")\n",
        "\n",
        "image_path = '/content/drive/MyDrive/data/charts/train_val'\n",
        "\n",
        "\n",
        "'''\n",
        "The below code helps in moving the respective images from the /train_val folder to the /alexnet resprective class folder.\n",
        "'''\n",
        "for file in os.listdir(image_path):\n",
        "  indx=int(file.split('.')[0])\n",
        "  file_path = os.path.join(image_path, file)\n",
        "  class_=lbl_df.iloc[indx,:][1]\n",
        "  target_path=os.path.join(pretain_path,class_)\n",
        "  if os.path.exists(os.path.join(pretain_path,class_,file)):\n",
        "    pass\n",
        "  else:\n",
        "    if class_=='dot_line':\n",
        "      shutil.copy(file_path, target_path)\n",
        "    if class_=='pie':\n",
        "      shutil.copy(file_path, target_path)\n",
        "    if class_=='hbar_categorical':\n",
        "      shutil.copy(file_path, target_path)\n",
        "    if class_=='line':\n",
        "      shutil.copy(file_path, target_path)\n",
        "    if class_=='vbar_categorical':\n",
        "      shutil.copy(file_path, target_path)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0IaqdYVh2rE",
        "outputId": "c8908939-2166-47b0-b85a-65b6bada4a2a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No need to create [Errno 17] File exists: '/content/drive/MyDrive/data/charts/alexnet'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transforms for the training and validation sets\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(size=224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize(size=256),\n",
        "    transforms.CenterCrop(size=224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "pretain_path='/content/drive/MyDrive/charts/alexnet/'\n",
        "train_dataset = ImageFolder(root=pretain_path, transform=train_transforms)\n",
        "\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "model = models.alexnet(pretrained=True)\n",
        "model.eval()\n"
      ],
      "metadata": {
        "id": "09Ohx7h3h746"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 5\n",
        "model.classifier[-1] = nn.Linear(in_features=4096, out_features=num_classes)\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "AE7mClTAiFyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=model.to(device)\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs = inputs.cuda()\n",
        "        labels = labels.cuda()\n",
        "        # print(inputs)\n",
        "        # print(labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, epoch_loss))\n"
      ],
      "metadata": {
        "id": "DqP1FD_eiHvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy on the validation set: {:.2f}%'.format(correct / total * 100))"
      ],
      "metadata": {
        "id": "Oppafb8YiM6z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}